{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### SCRIPT COMPLETO, FALTA SOMENTE COLOCAR AS 25 PERGUNTAS"
      ],
      "metadata": {
        "id": "a6NDarRUM_0X"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 870
        },
        "id": "bPnBdP6JyFAX",
        "outputId": "4b9ade25-710f-4cde-a684-c70af10a938e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Instalando bibliotecas necessárias...\n",
            "Instalação concluída.\n",
            "Bibliotecas importadas com sucesso!\n",
            "\n",
            "Conectando ao Google Drive...\n",
            "Mounted at /content/drive\n",
            "Google Drive conectado.\n",
            "Cliente OpenAI configurado com sucesso.\n",
            "\n",
            "Carregando base de conhecimento do cache do Google Drive...\n",
            "Base de conhecimento com 4120 chunks carregada com sucesso.\n",
            "\n",
            "Iniciando a geração de 3 respostas usando o GPT-4o-mini e a busca de alta qualidade.\n",
            "\n",
            "Processando Pergunta 1/1: 'Qual órgão do corpo humano é responsável por filtrar o sangu...'\n",
            "   - Gerando resposta para o Prompt Heurístico...\n",
            "\n",
            "   ========= RESPOSTA RECEBIDA (1-Prompt Heurístico) =========\n",
            "Os rins são os órgãos responsáveis por filtrar o sangue e produzir a urina. Eles desempenham um papel fundamental na excreção de resíduos e na regulação do equilíbrio de fluidos e eletrólitos no corpo. \n",
            "\n",
            "**Referências:** Livro urologia fundamental-09-09-10.pdf, Página: 19.\n",
            "   ========================================\n",
            "\n",
            "   - Gerando resposta para o Prompt CoT...\n",
            "\n",
            "   ========= RESPOSTA RECEBIDA (1-Prompt CoT) =========\n",
            "O órgão responsável por filtrar o sangue e produzir a urina é o rim. Os rins desempenham a função de filtrar os resíduos do sangue, resultando na formação da urina, que é então transportada para a bexiga através dos ureteres. Essa função é essencial para a regulação do equilíbrio hídrico e eletrolítico do corpo. \n",
            "\n",
            "**Referências:**\n",
            "Livro urologia fundamental-09-09-10.pdf, Página: 19\n",
            "   ========================================\n",
            "\n",
            "   - Gerando resposta para o Prompt Direto...\n",
            "\n",
            "   ========= RESPOSTA RECEBIDA (1-Prompt Direto) =========\n",
            "O órgão responsável por filtrar o sangue e produzir a urina é o rim.\n",
            "\n",
            "Referências: \n",
            "- Livro urologia fundamental-09-09-10.pdf, Página: 5\n",
            "   ========================================\n",
            "\n",
            "\n",
            "Geração de todas as respostas concluída!\n",
            "\n",
            "PASSO FINAL: Criando a planilha Excel com validação restrita...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<a href=\"data:application/vnd.openxmlformats-officedocument.spreadsheetml.sheet;base64,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\" download=\"instrumento_avaliacao_FINAL_corrigido.xlsx\">Clique aqui para baixar a planilha de avaliação (CORRIGIDA)</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Planilha finalizada e pronta para download.\n"
          ]
        }
      ],
      "source": [
        "# --- CÉLULA ÚNICA: SOLUÇÃO HÍBRIDA ADAPTADA (COM GUIA E AVALIAÇÃO ESTRUTURADA) ---\n",
        "\n",
        "# --- 1. INSTALAÇÕES E IMPORTAÇÕES ---\n",
        "print(\"Instalando bibliotecas necessárias...\")\n",
        "!pip install openai openpyxl PyMuPDF sentence-transformers numpy tiktoken -q\n",
        "print(\"Instalação concluída.\")\n",
        "\n",
        "import os\n",
        "import time\n",
        "import io\n",
        "import json\n",
        "import base64\n",
        "import fitz  # PyMuPDF\n",
        "from google.colab import drive, userdata\n",
        "import openai\n",
        "from openpyxl import Workbook\n",
        "from openpyxl.worksheet.datavalidation import DataValidation\n",
        "from openpyxl.styles import Font, Alignment, PatternFill, Border, Side\n",
        "from sentence_transformers import util\n",
        "import numpy as np\n",
        "import tiktoken\n",
        "from IPython.display import HTML, display\n",
        "print(\"Bibliotecas importadas com sucesso!\")\n",
        "\n",
        "# --- 2. CONFIGURAÇÃO DO AMBIENTE ---\n",
        "try:\n",
        "    print(\"\\nConectando ao Google Drive...\")\n",
        "    drive.mount('/content/drive')\n",
        "    print(\"Google Drive conectado.\")\n",
        "    API_KEY = userdata.get('OPENAI_API_KEY')\n",
        "    if not API_KEY: raise ValueError(\"API Key não encontrada nos Segredos do Colab.\")\n",
        "    client = openai.OpenAI(api_key=API_KEY)\n",
        "    print(\"Cliente OpenAI configurado com sucesso.\")\n",
        "except Exception as e:\n",
        "    print(f\"ERRO na configuração: {e}\")\n",
        "    raise SystemExit(\"Execução interrompida.\")\n",
        "\n",
        "# --- 3. DEFINIÇÕES DE PERGUNTAS E PROMPTS (COMPLETO) ---\n",
        "perguntas = [\n",
        "    \"Qual órgão do corpo humano é responsável por filtrar o sangue e produzir a urina?\", \"Por quanto tempo um homem pode ter incontinência urinária após uma cirurgia de retirada da próstata?\", \"Quais são os principais fatores de risco para a disfunção erétil?\", \"Como prevenir a incontinência urinária masculina?\", \"Qual é a função da bexiga urinária?\", \"Quais são os três principais tipos de incontinência urinária masculina?\", \"Qual prática complementar foi estudada para auxiliar no controle da incontinência urinária pós-prostatectomia radical?\", \"Ao receberem alta hospitalar, o que os pacientes submetidos à cirurgia, em sua grande maioria necessitam fazer?\", \"Qual tecnologia foi desenvolvida para auxiliar no tratamento da incontinência urinária pós-prostatectomia?\", \"Qual instrumento foi adaptado para avaliar a disfunção sexual em homens brasileiros com sintomas do trato urinário inferior?\", \"Segurar muito o xixi pode causar algum problema?\", \"Tem algum remédio que ajuda a não perder urina?\", \"Fazer exercício para o xixi parar de escapar funciona mesmo?\", \"Fazer muita força para urinar é normal?\", \"Incontinência tem cura ou vou ter isso pra sempre?\", \"Tomar muita água piora ou melhora o problema de xixi solto?\", \"O que posso fazer para não ter que levantar à noite toda hora pra urinar?\", \"Por que tenho vontade de urinar toda hora?\", \"O que posso fazer para não ter escapes de urina durante o dia?\", \"Beber cerveja piora a incontinência urinária?\", \"Fiz a cirurgia recentemente. Agora faço xixi sem querer quando dou risada ou espirro. Isso é normal?\", \"Por que às vezes meu pênis não fica duro como antes?\", \"Depois da cirurgia de próstata, ainda vou conseguir ter ereção?\", \"Ficar muito tempo sem fazer sexo pode causar impotência?\", \"Tenho evitado fazer sexo depois da cirurgia. Isso é bom?\"\n",
        "]\n",
        "\n",
        "prompt_template_heuristico = \"\"\"### **[INÍCIO DO PROMPT MESTRE]**\n",
        "\n",
        "**Seção 1: Definição da Persona e Missão**\n",
        "\n",
        "O assistente virtual operará como um modelo de linguagem especializado em recuperação pós-prostatectomia, saúde da próstata e incontinência urinária masculina. O seu objetivo é fornecer respostas precisas, relevantes, abrangentes e expressas com clareza. O assistente atua como uma fonte de informação para apoiar pacientes que passaram por prostatectomia radical.\n",
        "\n",
        "**Seção 2: Princípio de Fidelidade ao Contexto**\n",
        "\n",
        "A sua operação é governada pela diretriz da utilização exclusiva das informações contidas no `CONTEXTO RELEVANTE`. O assistente não deve consultar conhecimento externo, a sua base de dados de treinamento ou outras fontes de informação. Este princípio visa garantir a consistência e a fidelidade ao material de origem, que funciona como a fonte de verdade para a tarefa.\n",
        "\n",
        "**Seção 5: Formato da Resposta Final**\n",
        "\n",
        "A resposta final não deve conter menção às heurísticas, aos passos do raciocínio ou a qualquer metadado do processo. A resposta deve ser apresentada com base no conhecimento fornecido.\n",
        "\n",
        "O resultado deve ser:\n",
        "\n",
        "* Uma resposta textual coesa, adaptada para pacientes que passaram por prostatectomia e clara.\n",
        "* Redigida em português com no máximo 5 linhas para a resposta.\n",
        "* A resposta deve ser direta sem apresentar os detalhes de sua construção, seção, passos, etc.\n",
        "* **Citação da Fonte:** Ao final da resposta, incluir uma seção de \"Referências\" listando o nome do documento e o número da página de onde a informação foi extraída.\n",
        "\n",
        "**Seção 6: Execução da Tarefa**\n",
        "\n",
        "Com base no protocolo descrito, utilizar o `CONTEXTO RELEVANTE` para responder à `PERGUNTA`.\n",
        "\n",
        "**CONTEXTO RELEVANTE:**\n",
        "{contexto_relevante}\n",
        "\n",
        "**PERGUNTA:**\n",
        "{pergunta_aqui}\"\"\"\n",
        "prompt_template_cot = \"\"\"### **[INÍCIO DO PROMPT MESTRE]**\n",
        "\n",
        "**Seção 1: Definição da Persona e Missão**\n",
        "\n",
        "O assistente virtual operará como um modelo de linguagem especializado em recuperação pós-prostatectomia, saúde da próstata e incontinência urinária masculina. O seu objetivo é fornecer respostas precisas, relevantes, abrangentes e expressas com clareza. O assistente atua como uma fonte de informação para apoiar pacientes que passaram por prostatectomia radical.\n",
        "\n",
        "**Seção 2: Princípio de Fidelidade ao Contexto**\n",
        "\n",
        "A sua operação é governada pela diretriz da utilização exclusiva das informações contidas no `CONTEXTO RELEVANTE`. O assistente não deve consultar conhecimento externo, a sua base de dados de treinamento ou outras fontes de informação. Este princípio visa garantir a consistência e a fidelidade ao material de origem, que funciona como a fonte de verdade para a tarefa.\n",
        "\n",
        "**Seção 5: Formato da Resposta Final**\n",
        "\n",
        "A resposta final deve ser apresentada como um texto coeso que demonstre a Cadeia de Pensamento.\n",
        "\n",
        "O resultado deve incluir:\n",
        "\n",
        "* Uma resposta textual que apresente o percurso lógico até à conclusão.\n",
        "* Redigida em português com no máximo 5 linhas para a resposta.\n",
        "* Redação em português.\n",
        "* **Citação da Fonte:** Ao final da resposta, deve ser incluída uma seção de \"Referências\", listando o nome do documento (ex: livro, cartilha, apostila) e o número da página de onde a informação foi extraída.\n",
        "\n",
        "**Seção 6: Execução da Tarefa**\n",
        "\n",
        "Com base no protocolo descrito, deve ser utilizado o `CONTEXTO RELEVANTE` para responder à `PERGUNTA`.\n",
        "\n",
        "**CONTEXTO RELEVANTE:**\n",
        "{contexto_relevante}\n",
        "\n",
        "**PERGUNTA:**\n",
        "{pergunta_aqui}\"\"\"\n",
        "prompt_template_direto = \"\"\"Instrução: Responda à PERGUNTA abaixo utilizando exclusivamente as informações fornecidas no CONTEXTO RELEVANTE. A resposta deve ser direta, objetiva e formulada em português. Não utilize conhecimento externo. Ao final da resposta, inclua uma seção de \"Referências\" listando o nome do documento e o número da página de onde a informação principal foi extraída.\n",
        "\n",
        "---\n",
        "\n",
        "CONTEXTO RELEVANTE:\n",
        "{contexto_relevante}\n",
        "\n",
        "---\n",
        "\n",
        "PERGUNTA:\n",
        "{pergunta_aqui}\"\"\"\n",
        "\n",
        "# --- 4. FUNÇÕES DO SISTEMA RAG HÍBRIDO ---\n",
        "\n",
        "def criar_ou_carregar_base_conhecimento(caminho_pasta, client, force_recreate=False):\n",
        "    caminho_cache = '/content/drive/MyDrive/rag_cache_openai'\n",
        "    caminho_chunks = os.path.join(caminho_cache, 'chunks_data.json')\n",
        "    caminho_embeddings = os.path.join(caminho_cache, 'embeddings_openai.npy')\n",
        "    os.makedirs(caminho_cache, exist_ok=True)\n",
        "\n",
        "    if not force_recreate and os.path.exists(caminho_chunks) and os.path.exists(caminho_embeddings):\n",
        "        print(\"\\nCarregando base de conhecimento do cache do Google Drive...\")\n",
        "        with open(caminho_chunks, 'r', encoding='utf-8') as f:\n",
        "            chunks_com_metadata = json.load(f)\n",
        "        chunk_embeddings = np.load(caminho_embeddings)\n",
        "        print(f\"Base de conhecimento com {len(chunks_com_metadata)} chunks carregada com sucesso.\")\n",
        "        return chunks_com_metadata, chunk_embeddings\n",
        "\n",
        "    print(\"\\nCriando nova base de conhecimento (isso pode levar alguns minutos e terá custos de API)...\")\n",
        "    chunks_com_metadata = []\n",
        "    arquivos_pdf = [f for f in os.listdir(caminho_pasta) if f.lower().endswith('.pdf')]\n",
        "    print(f\"Encontrados {len(arquivos_pdf)} arquivos PDF para processar.\")\n",
        "\n",
        "    for nome_arquivo in arquivos_pdf:\n",
        "        caminho_completo = os.path.join(caminho_pasta, nome_arquivo)\n",
        "        try:\n",
        "            with fitz.open(caminho_completo) as doc:\n",
        "                for page_num, page in enumerate(doc):\n",
        "                    text = page.get_text(\"text\")\n",
        "                    paragrafos = [p.strip() for p in text.split('\\n\\n') if len(p.strip()) > 150]\n",
        "                    for p in paragrafos:\n",
        "                        chunks_com_metadata.append({\"texto\": p, \"fonte\": nome_arquivo, \"pagina\": page_num + 1})\n",
        "            print(f\"   - Processado '{nome_arquivo}' com sucesso.\")\n",
        "        except Exception as e:\n",
        "            print(f\"   - ERRO ao processar '{nome_arquivo}': {e}\")\n",
        "\n",
        "    if not chunks_com_metadata:\n",
        "        print(\"ERRO: Nenhum chunk de texto utilizável foi criado.\")\n",
        "        return None, None\n",
        "\n",
        "    print(f\"\\nTotal de {len(chunks_com_metadata)} chunks de texto criados.\")\n",
        "\n",
        "    print(\"Gerando embeddings em lotes com a API da OpenAI...\")\n",
        "    all_embeddings = []\n",
        "    embedding_model = \"text-embedding-3-small\"\n",
        "    tokenizer = tiktoken.encoding_for_model(embedding_model)\n",
        "    TOKEN_LIMIT_PER_REQUEST = 250000\n",
        "    current_batch_texts = []\n",
        "    current_batch_tokens = 0\n",
        "    try:\n",
        "        for chunk in chunks_com_metadata:\n",
        "            text = chunk['texto']\n",
        "            token_count = len(tokenizer.encode(text))\n",
        "            if current_batch_tokens + token_count > TOKEN_LIMIT_PER_REQUEST:\n",
        "                print(f\"   - Processando lote com {len(current_batch_texts)} chunks e {current_batch_tokens} tokens...\")\n",
        "                response = client.embeddings.create(input=current_batch_texts, model=embedding_model)\n",
        "                all_embeddings.extend([item.embedding for item in response.data])\n",
        "                current_batch_texts = [text]\n",
        "                current_batch_tokens = token_count\n",
        "                time.sleep(1)\n",
        "            else:\n",
        "                current_batch_texts.append(text)\n",
        "                current_batch_tokens += token_count\n",
        "        if current_batch_texts:\n",
        "            print(f\"   - Processando o último lote com {len(current_batch_texts)} chunks e {current_batch_tokens} tokens...\")\n",
        "            response = client.embeddings.create(input=current_batch_texts, model=embedding_model)\n",
        "            all_embeddings.extend([item.embedding for item in response.data])\n",
        "        chunk_embeddings = np.array(all_embeddings)\n",
        "        print(\"Geração de todos os embeddings concluída.\")\n",
        "    except Exception as e:\n",
        "        print(f\"ERRO CRÍTICO ao gerar embeddings: {e}\")\n",
        "        return None, None\n",
        "\n",
        "    print(\"Salvando base de conhecimento no cache do Google Drive...\")\n",
        "    with open(caminho_chunks, 'w', encoding='utf-8') as f:\n",
        "        json.dump(chunks_com_metadata, f, ensure_ascii=False, indent=4)\n",
        "    np.save(caminho_embeddings, chunk_embeddings)\n",
        "    print(\"Base de conhecimento criada e salva com sucesso.\")\n",
        "    return chunks_com_metadata, chunk_embeddings\n",
        "\n",
        "def buscar_contexto_relevante(query, chunks_data, chunk_embeddings, client, top_k=8):\n",
        "    query_embedding = client.embeddings.create(input=[query], model=\"text-embedding-3-small\").data[0].embedding\n",
        "    query_embedding_np = np.array([query_embedding], dtype=np.float32)\n",
        "    chunk_embeddings_np = np.array(chunk_embeddings, dtype=np.float32)\n",
        "    cos_scores = util.pytorch_cos_sim(query_embedding_np, chunk_embeddings_np)[0]\n",
        "    top_results_indices = np.argpartition(-cos_scores, range(top_k))[0:top_k]\n",
        "    contexto_formatado = \"\"\n",
        "    for i in top_results_indices:\n",
        "        info = chunks_data[i]\n",
        "        contexto_formatado += f\"---\\nFonte: {info['fonte']}, Página: {info['pagina']}\\nConteúdo: {info['texto']}\\n\"\n",
        "    return contexto_formatado\n",
        "\n",
        "def gerar_resposta_gpt4(prompt_final, client):\n",
        "    try:\n",
        "        response = client.chat.completions.create(\n",
        "            model=\"gpt-4o-mini\",\n",
        "            messages=[{\"role\": \"user\", \"content\": prompt_final}],\n",
        "            temperature=0.4\n",
        "        )\n",
        "        return response.choices[0].message.content\n",
        "    except Exception as e:\n",
        "        print(f\"   - ERRO ao chamar a API de Chat: {e}\")\n",
        "        return f\"[ERRO AO CHAMAR API: {e}]\"\n",
        "\n",
        "# --- FUNÇÃO PRINCIPAL DE CRIAÇÃO DA PLANILHA (CORRIGIDA) ---\n",
        "\n",
        "def criar_planilha_final(perguntas_lista, respostas_dict):\n",
        "    \"\"\"Cria a planilha Excel final, com validação de dados restrita e opções objetivas de classificação.\"\"\"\n",
        "    print(\"\\nPASSO FINAL: Criando a planilha Excel com validação restrita...\")\n",
        "    wb = Workbook()\n",
        "\n",
        "    # --- ABA 1: GUIA DE AVALIAÇÃO (ATUALIZADA) ---\n",
        "    ws_guia = wb.active\n",
        "    ws_guia.title = \"Guia de Avaliação\"\n",
        "\n",
        "    # Estilos\n",
        "    title_font = Font(bold=True, size=16, color=\"FFFFFF\")\n",
        "    title_fill = PatternFill(start_color=\"4F81BD\", end_color=\"4F81BD\", fill_type=\"solid\")\n",
        "    header_font = Font(bold=True, color=\"FFFFFF\")\n",
        "    header_fill = PatternFill(start_color=\"1F497D\", end_color=\"1F497D\", fill_type=\"solid\")\n",
        "    section_font = Font(bold=True, size=14)\n",
        "\n",
        "    # Título Principal e Objetivo\n",
        "    ws_guia.merge_cells('A1:B1')\n",
        "    ws_guia['A1'].value = \"Guia para Avaliação das Respostas do Modelo de Linguagem\"\n",
        "    ws_guia['A1'].font = title_font; ws_guia['A1'].fill = title_fill; ws_guia['A1'].alignment = Alignment(horizontal='center', vertical='center')\n",
        "    ws_guia.row_dimensions[1].height = 30\n",
        "    ws_guia.merge_cells('A2:B2')\n",
        "    ws_guia['A2'].value = \"Objetivo: Avaliar a qualidade e a eficácia de respostas geradas por Inteligência Artificial. O processo é dividido em 2 etapas para cada pergunta principal.\"\n",
        "    ws_guia['A2'].alignment = Alignment(wrap_text=True, vertical='top'); ws_guia.row_dimensions[2].height = 40\n",
        "\n",
        "    # Etapa 1\n",
        "    ws_guia.merge_cells('A4:B4'); ws_guia['A4'].value = \"Etapa 1: Avaliação de cada Resposta Individual\"; ws_guia['A4'].font = section_font; ws_guia['A4'].alignment = Alignment(vertical='center'); ws_guia.row_dimensions[4].height = 22\n",
        "    ws_guia['A5'] = \"Pergunta para a Avaliadora\"; ws_guia['A5'].font = header_font; ws_guia['A5'].fill = header_fill\n",
        "    ws_guia['B5'] = \"Opções de Resposta (Menu de Seleção)\"; ws_guia['B5'].font = header_font; ws_guia['B5'].fill = header_fill\n",
        "    questoes_etapa1 = [\n",
        "        (\"1. Esta resposta está correta?\", \"Totalmente / Em parte / Não\"),\n",
        "        (\"2. A resposta resolve a dúvida do paciente por completo?\", \"Resolve tudo / Resolve em parte / Não resolve\"),\n",
        "        (\"3. A linguagem é fácil para um paciente entender?\", \"Muito fácil / Razoavelmente Fácil / Resposta Confusa / Resposta Técnica\"),\n",
        "        (\"4. A resposta cita a fonte da informação?\", \"Citou a fonte e a página / Citou apenas a fonte / Não citou a fonte / Citou a fonte errada\"),\n",
        "        (\"5. A resposta possui alguma informação inventada?\", \"Sim / Não\"),\n",
        "        (\"6. Observações sobre esta resposta específica:\", \"(Campo de texto livre)\")\n",
        "    ]\n",
        "    for i, (q, r) in enumerate(questoes_etapa1, 6):\n",
        "        ws_guia[f'A{i}'] = q; ws_guia[f'B{i}'] = r; ws_guia.row_dimensions[i].height = 25\n",
        "        ws_guia[f'A{i}'].alignment = Alignment(vertical='center', wrap_text=True); ws_guia[f'B{i}'].alignment = Alignment(vertical='center', wrap_text=True)\n",
        "\n",
        "    # Etapa 2 (com texto da pergunta 3 atualizado para refletir o menu de seleção)\n",
        "    ws_guia.merge_cells('A12:B12')\n",
        "    ws_guia.merge_cells('A13:B13'); ws_guia['A13'].value = \"Etapa 2: Síntese Final (após avaliar as 3 respostas de uma pergunta)\"; ws_guia['A13'].font = section_font; ws_guia['A13'].alignment = Alignment(vertical='center'); ws_guia.row_dimensions[13].height = 22\n",
        "    ws_guia['A14'] = \"Pergunta para a Avaliadora\"; ws_guia['A14'].font = header_font; ws_guia['A14'].fill = header_fill\n",
        "    ws_guia['B14'] = \"Opções de Resposta\"; ws_guia['B14'].font = header_font; ws_guia['B14'].fill = header_fill\n",
        "    questoes_etapa2 = [\n",
        "        (\"1. No geral, qual o prompt ?\", \"Prompt Heurístico / Prompt CoT / Prompt Direto\"),\n",
        "        (\"2. Justifique a resposta anterior.\", \"(Campo de texto livre)\"),\n",
        "        (\"3. Classifique os 3 prompts do melhor para a pior:\", \"(Menu de seleção com 6 ordens possíveis)\") # Texto atualizado\n",
        "    ]\n",
        "    for i, (q, r) in enumerate(questoes_etapa2, 15):\n",
        "        ws_guia[f'A{i}'] = q; ws_guia[f'B{i}'] = r; ws_guia.row_dimensions[i].height = 25\n",
        "        ws_guia[f'A{i}'].alignment = Alignment(vertical='center', wrap_text=True); ws_guia[f'B{i}'].alignment = Alignment(vertical='center', wrap_text=True)\n",
        "\n",
        "    ws_guia.column_dimensions['A'].width = 55; ws_guia.column_dimensions['B'].width = 65\n",
        "\n",
        "    # --- ABA 2: AVALIAÇÃO DAS RESPOSTAS (COM VALIDAÇÃO RESTRITA) ---\n",
        "    ws = wb.create_sheet(\"Avaliação das Respostas\")\n",
        "    header = [\n",
        "        \"ID Pergunta\", \"Pergunta / Abordagem\", \"Resposta Gerada\", \"1. Esta resposta está correta?\",\n",
        "        \"2. A resposta resolve a dúvida do paciente por completo?\", \"3. A linguagem é fácil para um paciente entender?\",\n",
        "        \"4. A resposta cita a fonte da informação?\", \"5. A resposta possui alguma informação inventada?\",\n",
        "        \"6. Observações sobre esta resposta específica:\"\n",
        "    ]\n",
        "    ws.append(header)\n",
        "\n",
        "    # Estilos\n",
        "    header_font_eval = Font(bold=True, color=\"FFFFFF\"); header_fill_eval = PatternFill(start_color=\"4F81BD\", end_color=\"4F81BD\", fill_type=\"solid\")\n",
        "    question_fill = PatternFill(start_color=\"DCE6F1\", end_color=\"DCE6F1\", fill_type=\"solid\")\n",
        "    sintese_fill = PatternFill(start_color=\"F2F2F2\", end_color=\"F2F2F2\", fill_type=\"solid\")\n",
        "    sintese_header_fill = PatternFill(start_color=\"BFBFBF\", end_color=\"BFBFBF\", fill_type=\"solid\")\n",
        "    thin_border = Border(left=Side(style='thin'), right=Side(style='thin'), top=Side(style='thin'), bottom=Side(style='thin'))\n",
        "    for cell in ws[1]: cell.font = header_font_eval; cell.fill = header_fill_eval; cell.alignment = Alignment(horizontal='center', vertical='center', wrap_text=True)\n",
        "\n",
        "    # --- INÍCIO DA ALTERAÇÃO: Função para criar DataValidation RESTRITA ---\n",
        "    def create_restricted_dv(formula):\n",
        "        dv = DataValidation(type=\"list\", formula1=formula, allow_blank=True)\n",
        "        dv.error = 'Por favor, selecione um valor da lista.'\n",
        "        dv.errorTitle = 'Entrada Inválida'\n",
        "        dv.prompt = 'Selecione uma opção da lista.'\n",
        "        dv.promptTitle = 'Seleção de Opção'\n",
        "        dv.showErrorMessage = True\n",
        "        dv.errorStyle = 'stop' # A MUDANÇA CHAVE: Impede digitação de valores fora da lista\n",
        "        return dv\n",
        "    # --- FIM DA ALTERAÇÃO ---\n",
        "\n",
        "    dv1 = create_restricted_dv('\"Totalmente,Em parte,Não\"')\n",
        "    dv2 = create_restricted_dv('\"Resolve tudo,Resolve em parte,Não resolve\"')\n",
        "    dv3 = create_restricted_dv('\"Muito fácil,Razoavelmente Fácil, Confusa, Resposta técnica\"')\n",
        "    dv4 = create_restricted_dv('\"Cita a fonte e a página,Citou apenas a fonte,Não citou a fonte, Citou a fonte errada\"')\n",
        "    dv5 = create_restricted_dv('\"Sim,Não\"')\n",
        "    dv_sintese_1 = create_restricted_dv('\"Prompt Heurístico,Prompt CoT,Prompt Direto\"')\n",
        "\n",
        "    # --- INÍCIO DA ALTERAÇÃO: Lista de opções para a pergunta de classificação ---\n",
        "    classificacao_options = [\n",
        "        \"1º Heurístico > 2º CoT > 3º Direto\", \"1º Heurístico > 2º Direto > 3º CoT\",\n",
        "        \"1º CoT > 2º Heurístico > 3º Direto\", \"1º CoT > 2º Direto > 3º Heurístico\",\n",
        "        \"1º Direto > 2º Heurístico > 3º CoT\", \"1º Direto > 2º CoT > 3º Heurístico\"\n",
        "    ]\n",
        "    # Converte a lista Python para o formato de string que o Excel espera: \"Opção 1,Opção 2,...\"\n",
        "    dv_sintese_3 = create_restricted_dv(f'\"{\",\".join(classificacao_options)}\"')\n",
        "    # --- FIM DA ALTERAÇÃO ---\n",
        "\n",
        "    ws.add_data_validation(dv1); ws.add_data_validation(dv2); ws.add_data_validation(dv3)\n",
        "    ws.add_data_validation(dv4); ws.add_data_validation(dv5); ws.add_data_validation(dv_sintese_1)\n",
        "    ws.add_data_validation(dv_sintese_3) # Adiciona a nova validação à planilha\n",
        "\n",
        "    # Preenchimento\n",
        "    current_row = 2\n",
        "    prompt_types = [\"Prompt Heurístico\", \"Prompt CoT\", \"Prompt Direto\"]\n",
        "    for i, pergunta_texto in enumerate(perguntas_lista, 1):\n",
        "        start_merge_row = current_row\n",
        "        ws.cell(row=current_row, column=1, value=i)\n",
        "        ws.cell(row=current_row, column=2, value=pergunta_texto)\n",
        "        for col in range(1, len(header) + 1): ws.cell(row=current_row, column=col).fill = question_fill; ws.cell(row=current_row, column=col).font = Font(bold=True)\n",
        "        current_row += 1\n",
        "\n",
        "        for tipo in prompt_types:\n",
        "            id_resposta = f\"{i}-{tipo}\"; ws.cell(row=current_row, column=2, value=f\"Abordagem: {tipo}\")\n",
        "            ws.cell(row=current_row, column=3, value=respostas_dict.get(id_resposta, \"[RESPOSTA NÃO ENCONTRADA]\"))\n",
        "            for col in range(2, len(header) + 2): ws.cell(row=current_row, column=col).border = thin_border\n",
        "            dv1.add(ws[f'D{current_row}']); dv2.add(ws[f'E{current_row}']); dv3.add(ws[f'F{current_row}'])\n",
        "            dv4.add(ws[f'G{current_row}']); dv5.add(ws[f'H{current_row}'])\n",
        "            current_row += 1\n",
        "\n",
        "        ws.merge_cells(start_row=current_row, start_column=2, end_row=current_row, end_column=len(header))\n",
        "        cell_sintese = ws.cell(row=current_row, column=2, value=\"Etapa 2: Síntese Final\")\n",
        "        cell_sintese.fill = sintese_header_fill; cell_sintese.font = Font(bold=True); cell_sintese.alignment = Alignment(horizontal='center')\n",
        "        current_row += 1\n",
        "\n",
        "        # --- INÍCIO DA ALTERAÇÃO: Lógica para aplicar a validação correta a cada pergunta de síntese ---\n",
        "        sintese_rows_config = [\n",
        "            (\"1. No geral, qual o prompt ?\", 'geral'),\n",
        "            (\"2. Justifique a resposta anterior.\", 'livre'), # 'livre' significa sem validação\n",
        "            (\"3. Classifique os 3 prompts do melhor para a pior:\", 'classificacao')\n",
        "        ]\n",
        "        for texto_sintese, tipo_dv in sintese_rows_config:\n",
        "            ws.cell(row=current_row, column=2, value=texto_sintese).fill = sintese_fill\n",
        "            ws.merge_cells(start_row=current_row, start_column=3, end_row=current_row, end_column=len(header))\n",
        "            cell_to_fill = ws.cell(row=current_row, column=3); cell_to_fill.fill = sintese_fill\n",
        "            # Aplica a validação de dados correta com base no tipo\n",
        "            if tipo_dv == 'geral':\n",
        "                dv_sintese_1.add(cell_to_fill)\n",
        "            elif tipo_dv == 'classificacao':\n",
        "                dv_sintese_3.add(cell_to_fill)\n",
        "            # Se tipo_dv for 'livre', nenhuma validação é adicionada\n",
        "            current_row += 1\n",
        "        # --- FIM DA ALTERAÇÃO ---\n",
        "\n",
        "        ws.merge_cells(start_row=start_merge_row, start_column=1, end_row=current_row - 1, end_column=1)\n",
        "        ws.cell(row=start_merge_row, column=1).alignment = Alignment(horizontal='center', vertical='center')\n",
        "\n",
        "    # Ajustes finais da planilha\n",
        "    ws.column_dimensions['B'].width = 45; ws.column_dimensions['C'].width = 90; ws.column_dimensions['D'].width = 25\n",
        "    ws.column_dimensions['E'].width = 30; ws.column_dimensions['F'].width = 30; ws.column_dimensions['G'].width = 30\n",
        "    ws.column_dimensions['H'].width = 25; ws.column_dimensions['I'].width = 60\n",
        "    for row in ws.iter_rows(min_row=2):\n",
        "        for cell in row: cell.alignment = Alignment(wrap_text=True, vertical='top')\n",
        "\n",
        "    ws.freeze_panes = 'A2'\n",
        "\n",
        "    # Geração do link para download\n",
        "    virtual_workbook = io.BytesIO(); wb.save(virtual_workbook)\n",
        "    b64 = base64.b64encode(virtual_workbook.getvalue()).decode('utf-8')\n",
        "    file_name = \"instrumento_avaliacao_FINAL_corrigido.xlsx\"\n",
        "    link_html = f'<a href=\"data:application/vnd.openxmlformats-officedocument.spreadsheetml.sheet;base64,{b64}\" download=\"{file_name}\">Clique aqui para baixar a planilha de avaliação (CORRIGIDA)</a>'\n",
        "    display(HTML(link_html))\n",
        "    print(\"\\nPlanilha finalizada e pronta para download.\")\n",
        "\n",
        "# --- 5. EXECUÇÃO PRINCIPAL ---\n",
        "if __name__ == '__main__':\n",
        "    # ATENÇÃO: Substitua pelo caminho correto no seu Google Drive\n",
        "    caminho_da_pasta_pdfs = '/content/drive/MyDrive/materiais para referencia/referencias prompt IUProst'\n",
        "\n",
        "    # Mantenha como False para usar o cache e economizar custos de API, ou True para forçar a releitura dos PDFs\n",
        "    FORCAR_RECRIAÇÃO = False\n",
        "\n",
        "    chunks_data, chunk_embeddings = criar_ou_carregar_base_conhecimento(caminho_da_pasta_pdfs, client, force_recreate=FORCAR_RECRIAÇÃO)\n",
        "\n",
        "    if chunks_data is not None:\n",
        "        respostas_finais = {}\n",
        "        total_perguntas = len(perguntas)\n",
        "        total_geracoes = total_perguntas * 3\n",
        "        print(f\"\\nIniciando a geração de {total_geracoes} respostas usando o GPT-4o-mini e a busca de alta qualidade.\")\n",
        "\n",
        "        prompts = {\n",
        "            \"Prompt Heurístico\": prompt_template_heuristico,\n",
        "            \"Prompt CoT\": prompt_template_cot,\n",
        "            \"Prompt Direto\": prompt_template_direto,\n",
        "        }\n",
        "\n",
        "        for i, pergunta in enumerate(perguntas, 1):\n",
        "            print(f\"\\nProcessando Pergunta {i}/{total_perguntas}: '{pergunta[:60]}...'\")\n",
        "            contexto = buscar_contexto_relevante(pergunta, chunks_data, chunk_embeddings, client)\n",
        "\n",
        "            for tipo, prompt_template in prompts.items():\n",
        "                print(f\"   - Gerando resposta para o {tipo}...\")\n",
        "                prompt_final = prompt_template.format(contexto_relevante=contexto, pergunta_aqui=pergunta)\n",
        "                resposta_atual = gerar_resposta_gpt4(prompt_final, client)\n",
        "                id_resposta = f\"{i}-{tipo}\"\n",
        "\n",
        "                print(f\"\\n   ========= RESPOSTA RECEBIDA ({id_resposta}) =========\")\n",
        "                print(resposta_atual)\n",
        "                print(\"   ========================================\\n\")\n",
        "\n",
        "                respostas_finais[id_resposta] = resposta_atual\n",
        "                time.sleep(10) # Pausa para não sobrecarregar a API\n",
        "\n",
        "        print(\"\\nGeração de todas as respostas concluída!\")\n",
        "        criar_planilha_final(perguntas, respostas_finais)\n",
        "    else:\n",
        "        print(\"\\nERRO CRÍTICO: A execução foi interrompida porque a base de conhecimento não pôde ser criada ou carregada.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### OUTRA VERSÃO POIS A ANTERIOR FALTOU ALGUMAS ANÁLISES"
      ],
      "metadata": {
        "id": "oUysYAQZz8pk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# =================================================================================\n",
        "# SCRIPT DE ANÁLISE ESTATÍSTICA - GERADOR DE CAPÍTULO DE LATEX (VERSÃO 6.5 - FINAL CORRIGIDO)\n",
        "# ESTA VERSÃO CORRIGE A LEITURA DE ARQUIVOS .XLSX, REINTRODUZINDO O PARÂMETRO 'sheet_name'.\n",
        "# =================================================================================\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "# PASSO 0: INSTALAÇÃO DE DEPENDÊNCIAS E IMPORTAÇÃO\n",
        "# ------------------------------------------------------------------------------\n",
        "# Tenta importar as bibliotecas e, se não existirem, instala-as.\n",
        "try:\n",
        "    import pandas as pd\n",
        "    import numpy as np\n",
        "    import statsmodels\n",
        "    import scipy\n",
        "    import textstat\n",
        "    import pytz\n",
        "    from google.colab import files\n",
        "except ImportError:\n",
        "    print(\"Instalando as bibliotecas necessárias (pandas, openpyxl, statsmodels, scipy, textstat, pytz)...\")\n",
        "    import subprocess\n",
        "    import sys\n",
        "    # A instalação de openpyxl é necessária para pd.read_excel\n",
        "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"pandas\", \"openpyxl\", \"statsmodels\", \"scipy\", \"textstat\", \"pytz\"])\n",
        "    print(\"Instalação concluída. Por favor, execute a célula novamente para carregar os módulos.\")\n",
        "    # Força a interrupção para que o usuário possa reexecutar a célula.\n",
        "    exit()\n",
        "\n",
        "from statsmodels.stats.inter_rater import fleiss_kappa\n",
        "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
        "from scipy.stats import chi2_contingency, f_oneway, levene\n",
        "import io\n",
        "import os\n",
        "import traceback\n",
        "from datetime import datetime\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "# PASSO 1: UPLOAD E PREPARAÇÃO DOS DADOS\n",
        "# ------------------------------------------------------------------------------\n",
        "print(\"--- PASSO 1: UPLOAD E PREPARAÇÃO DOS DADOS ---\")\n",
        "\n",
        "print(\"\\nPor favor, faça o upload de UM OU MAIS arquivos de avaliação (.xlsx ou .csv).\")\n",
        "uploaded = files.upload()\n",
        "\n",
        "if not uploaded:\n",
        "    print(\"\\nERRO: Nenhum arquivo foi enviado. Por favor, execute o script novamente e faça o upload de pelo menos um arquivo.\")\n",
        "else:\n",
        "    # Bloco principal que executa toda a lógica após o upload\n",
        "    try:\n",
        "        # =================================================================\n",
        "        # 1.1 LEITURA E PROCESSAMENTO DOS DADOS\n",
        "        # =================================================================\n",
        "        print(f\"\\nLendo e processando {len(uploaded)} arquivo(s)...\")\n",
        "        all_processed_dfs = []\n",
        "\n",
        "        def preprocess_df(df, avaliadora_nome):\n",
        "            \"\"\"Prepara e limpa o dataframe de cada avaliadora.\"\"\"\n",
        "            df['Avaliadora'] = avaliadora_nome\n",
        "\n",
        "            # Extrai a abordagem e preenche para as linhas seguintes\n",
        "            df['Abordagem'] = df['Pergunta / Abordagem'].apply(lambda x: x.split(': ')[1] if isinstance(x, str) and 'Abordagem:' in x else np.nan)\n",
        "            df['Abordagem'] = df['Abordagem'].ffill()\n",
        "\n",
        "            # Cria um ID único para cada pergunta para agrupar as 3 respostas\n",
        "            is_question_row = df['Pergunta / Abordagem'].str.contains('Abordagem:', na=False)\n",
        "            df['ID_Pergunta'] = is_question_row.cumsum()\n",
        "\n",
        "            # Renomeia as colunas de avaliação para nomes mais simples\n",
        "            rename_map = {\n",
        "                '1. Esta resposta é segura e correta? (Se a resposta é confiável e válida para o paciente)': 'Seguranca e Correcao',\n",
        "                '2. A resposta resolve a dúvida do paciente por completo?': 'Resolucao da Duvida',\n",
        "                '3. A linguagem é de fácil entendimento para um paciente?': 'Facilidade de Entendimento',\n",
        "                '4. A resposta cita a fonte da informação?': 'Citacao da Fonte',\n",
        "                '5. A resposta possui alguma informação inventada?': 'Informacao Inventada'\n",
        "            }\n",
        "\n",
        "            df_clean = df.rename(columns=rename_map)\n",
        "\n",
        "            # Garante que a coluna 'Resposta Gerada' existe\n",
        "            if 'Resposta Gerada' not in df_clean.columns:\n",
        "                df_clean['Resposta Gerada'] = df_clean['Pergunta / Abordagem']\n",
        "\n",
        "            # Filtra apenas as linhas que contêm avaliações\n",
        "            if 'Seguranca e Correcao' in df_clean.columns:\n",
        "                df_clean = df_clean[df_clean['Seguranca e Correcao'].notna()].copy()\n",
        "            else:\n",
        "                 raise KeyError(\"A coluna de avaliação 'Seguranca e Correcao' não foi encontrada. Verifique os nomes das colunas no arquivo.\")\n",
        "\n",
        "            return df_clean\n",
        "\n",
        "        for i, (filename, content) in enumerate(uploaded.items()):\n",
        "            print(f\"  - Processando '{filename}' como Avaliador(a) {i+1}...\")\n",
        "            file_extension = os.path.splitext(filename)[1]\n",
        "            try:\n",
        "                if file_extension == '.xlsx':\n",
        "                     # CORREÇÃO CRÍTICA: REINSERINDO O PARÂMETRO 'sheet_name'\n",
        "                     df_raw = pd.read_excel(io.BytesIO(content), sheet_name='Avaliação das Respostas')\n",
        "                elif file_extension == '.csv':\n",
        "                    try:\n",
        "                        df_raw = pd.read_csv(io.BytesIO(content), encoding='utf-8')\n",
        "                    except UnicodeDecodeError:\n",
        "                        df_raw = pd.read_csv(io.BytesIO(content), encoding='latin-1')\n",
        "                else:\n",
        "                    print(f\"    AVISO: Formato de arquivo '{file_extension}' não suportado para '{filename}'. Pulando.\")\n",
        "                    continue\n",
        "\n",
        "                avaliadora_nome = f\"Avaliadora {i+1}\"\n",
        "                processed_df = preprocess_df(df_raw, avaliadora_nome)\n",
        "                all_processed_dfs.append(processed_df)\n",
        "            except Exception as e:\n",
        "                print(f\"    ERRO ao processar o arquivo {filename}: {e}\")\n",
        "                print(\"    Verifique se o arquivo tem a aba 'Avaliação das Respostas' e as colunas corretas.\")\n",
        "\n",
        "\n",
        "        if not all_processed_dfs:\n",
        "            raise ValueError(\"Nenhum arquivo de avaliação pôde ser processado. O script será encerrado.\")\n",
        "\n",
        "        df_total_consolidado = pd.concat(all_processed_dfs, ignore_index=True)\n",
        "        # Normalização dos valores das colunas de critérios\n",
        "        for col in ['Seguranca e Correcao', 'Resolucao da Duvida', 'Facilidade de Entendimento', 'Citacao da Fonte', 'Informacao Inventada']:\n",
        "            if col in df_total_consolidado.columns and pd.api.types.is_string_dtype(df_total_consolidado[col]):\n",
        "                 df_total_consolidado[col] = df_total_consolidado[col].str.strip().str.lower()\n",
        "\n",
        "        print(\"Dados processados com sucesso.\")\n",
        "\n",
        "        # =================================================================\n",
        "        # 1.2 FUNÇÕES DE GERAÇÃO DE LATEX\n",
        "        # =================================================================\n",
        "        def escape_latex(text):\n",
        "            if not isinstance(text, str): return text\n",
        "            return text.replace('&', '\\\\&').replace('%', '\\\\%').replace('$', '\\\\$').replace('#', '\\\\#').replace('_', '\\\\_').replace('{', '\\\\{').replace('}', '\\\\}').replace('~', '\\\\textasciitilde{}').replace('^', '\\\\textasciicircum{}').replace('\\\\', '\\\\textbackslash{}')\n",
        "\n",
        "        def generate_descriptive_table_latex(df_crosstab, caption, label):\n",
        "            df_crosstab_copy = df_crosstab.copy()\n",
        "            df_crosstab_copy.index.name = 'Tipo de Prompt'\n",
        "            df_crosstab_copy.columns = [escape_latex(str(c).capitalize()) for c in df_crosstab_copy.columns]\n",
        "\n",
        "            df_total = df_crosstab_copy.sum(axis=1)\n",
        "            df_percent = df_crosstab_copy.div(df_total, axis=0).fillna(0) * 100\n",
        "\n",
        "            df_formatted = pd.DataFrame(index=df_crosstab_copy.index)\n",
        "            for col in df_crosstab_copy.columns:\n",
        "                df_formatted[col] = df_crosstab_copy[col].astype(str) + \" (\" + df_percent[col].map('{:.1f}\\\\%'.format) + \")\"\n",
        "\n",
        "            return df_formatted.reset_index().to_latex(index=False, caption=caption, label=label, position='H', escape=False)\n",
        "\n",
        "        def generate_pgfplot_bar(contingency_table, title, xlabel, ylabel, criterion_name):\n",
        "            ct_for_pgf = contingency_table.copy().reset_index()\n",
        "            clean_cols = [''.join(e for e in str(c) if e.isalnum() or e == '_') for c in ct_for_pgf.columns]\n",
        "            ct_for_pgf.columns = clean_cols\n",
        "\n",
        "            pgf_data_str = ct_for_pgf.to_csv(index=False, sep=',')\n",
        "\n",
        "            safe_name = ''.join(e for e in criterion_name if e.isalnum())\n",
        "            data_id = f\"dados{safe_name}\"\n",
        "\n",
        "            latex_code = [f\"\\\\pgfplotstableread[col sep=comma]{{{pgf_data_str}}}{{\\\\{data_id}}}\"]\n",
        "\n",
        "            legend_entries = [escape_latex(str(c).capitalize()) for c in contingency_table.columns]\n",
        "            legend_str = \", \".join(legend_entries)\n",
        "\n",
        "            x_coord_col_name = ct_for_pgf.columns[0]\n",
        "\n",
        "            symbolic_coords = [item.replace('_', ' ') for item in contingency_table.index]\n",
        "\n",
        "            latex_code.extend([\n",
        "                \"\\\\begin{figure}[H]\", \"\\\\centering\", \"\\\\begin{tikzpicture}\",\n",
        "                \"\\\\begin{axis}[\",\n",
        "                f\"    title={{{escape_latex(title)}}},\", \"ybar stacked,\", \"bar width=0.8cm,\", f\"enlarge x limits={{0.25}},\",\n",
        "                f\"    xlabel={{{escape_latex(xlabel)}}},\", f\"    ylabel={{{escape_latex(ylabel)}}},\",\n",
        "                f\"    symbolic x coords={{{', '.join(symbolic_coords)}}},\",\n",
        "                \"    xtick=data,\", \"x tick label style={rotate=45, anchor=east},\",\n",
        "                \"    legend style={at={(0.5,1.1)}, anchor=south, legend columns=-1, /tikz/every even column/.append style={column sep=0.5cm}}\",\n",
        "                \"]\"\n",
        "            ])\n",
        "            for col_name in ct_for_pgf.columns[1:]:\n",
        "                latex_code.append(f\"\\\\addplot table [x={x_coord_col_name}, y={col_name}] {{\\\\{data_id}}};\")\n",
        "            latex_code.extend([\n",
        "                f\"\\\\legend{{{legend_str}}}\", \"\\\\end{axis}\", \"\\\\end{tikzpicture}\",\n",
        "                f\"\\\\caption{{Distribuição das avaliações para o critério “{escape_latex(criterion_name)}”.}}\",\n",
        "                f\"\\\\label{{fig:{safe_name}}}\", \"\\\\end{figure}\"\n",
        "            ])\n",
        "            return \"\\n\".join(latex_code)\n",
        "\n",
        "        def generate_pgfplot_boxplot(df_scores, value_col, title, xlabel, ylabel, caption, label):\n",
        "            latex_code = [\n",
        "                \"\\\\begin{figure}[H]\", \"\\\\centering\", \"\\\\begin{tikzpicture}\",\n",
        "                \"\\\\begin{axis}[\",\n",
        "                f\"    title={{{escape_latex(title)}}},\", f\"    xlabel={{{escape_latex(xlabel)}}},\", f\"    ylabel={{{escape_latex(ylabel)}}},\",\n",
        "                \"    boxplot/draw direction=y,\", \"xtick={1,2,3},\",\n",
        "                \"    xticklabels={{Prompt CoT}, {Prompt Direto}, {Prompt Heurístico}},\",\n",
        "                \"    x tick label style={rotate=45, anchor=east}\",\n",
        "                \"]\"\n",
        "            ]\n",
        "            prompt_order = ['Prompt CoT', 'Prompt Direto', 'Prompt Heurístico']\n",
        "            for abordagem in prompt_order:\n",
        "                scores = df_scores[df_scores['Abordagem'] == abordagem][value_col].dropna()\n",
        "                if not scores.empty:\n",
        "                    scores_str = ' \\\\\\\\ '.join(map(lambda x: f\"{x:.2f}\", scores))\n",
        "                    latex_code.append(f\"\\\\addplot+ [boxplot] table [row sep=\\\\\\\\, y index=0] {{ data \\\\\\\\ {scores_str} \\\\\\\\ }};\")\n",
        "            latex_code.extend([\n",
        "                \"\\\\end{axis}\", \"\\\\end{tikzpicture}\",\n",
        "                f\"\\\\caption{{{escape_latex(caption)}}}\",\n",
        "                f\"\\\\label{{fig:{label}}}\", \"\\\\end{figure}\"\n",
        "            ])\n",
        "            return \"\\n\".join(latex_code)\n",
        "\n",
        "        def generate_tukey_latex(tukey_results, caption, label):\n",
        "            df_tukey = pd.read_html(tukey_results.summary().as_html(), header=0)[0]\n",
        "            df_tukey = df_tukey.rename(columns={'p-adj': 'p-ajustado', 'meandiff': 'dif. médias'})\n",
        "            df_tukey['dif. médias'] = df_tukey['dif. médias'].map('{:.2f}'.format)\n",
        "            df_tukey['p-ajustado'] = df_tukey['p-ajustado'].map('{:.4f}'.format)\n",
        "            df_tukey['reject'] = df_tukey['reject'].replace({True: 'Sim', False: 'Não'})\n",
        "            df_tukey = df_tukey.rename(columns={'reject': 'Rejeita H0 (p<0.05)'})\n",
        "            df_tukey.columns = [escape_latex(c) for c in df_tukey.columns]\n",
        "            return df_tukey.to_latex(index=False, caption=caption, label=label, position='H', escape=False)\n",
        "\n",
        "        # =================================================================\n",
        "        # 2. INÍCIO DA GERAÇÃO DO RELATÓRIO EM LATEX\n",
        "        # =================================================================\n",
        "        print(\"\\nIniciando a geração do relatório em LaTeX...\")\n",
        "        latex_output = []\n",
        "\n",
        "        tz_br = pytz.timezone('America/Sao_Paulo')\n",
        "        timestamp = datetime.now(tz_br).strftime('%Y-%m-%d %H:%M:%S')\n",
        "\n",
        "        latex_output.append(\n",
        "            fr\"\"\"% ===================================================================\n",
        "% INÍCIO DO CAPÍTULO DE RESULTADOS GERADO AUTOMATICAMENTE\n",
        "% Gerado em: {timestamp}\n",
        "% Análise baseada em {len(uploaded)} arquivo(s) de avaliação.\n",
        "% Versão do Script: 6.5 (Final Corrigido)\n",
        "% ===================================================================\n",
        "%\n",
        "% CERTIFIQUE-SE DE QUE OS SEGUINTES PACOTES ESTÃO NO SEU ARQUIVO .tex PRINCIPAL:\n",
        "% \\usepackage{{booktabs}}\n",
        "% \\usepackage{{float}}\n",
        "% \\usepackage{{tikz}}\n",
        "% \\usepackage{{pgfplots}}\n",
        "% \\pgfplotsset{{compat=1.18}}\n",
        "%\n",
        "% ===================================================================\n",
        "\n",
        "\\chapter{{Resultados}}\n",
        "\\label{{chap:resultados}}\n",
        "\n",
        "Neste capítulo, são apresentados os resultados das análises estatísticas realizadas sobre as avaliações das respostas geradas por diferentes tipos de prompts. A análise aborda a distribuição geral das avaliações, a concordância entre os avaliadores, uma comparação da qualidade das respostas entre os prompts e uma avaliação objetiva da legibilidade dos textos.\n",
        "\"\"\"\n",
        "        )\n",
        "\n",
        "        evaluation_criteria = {\n",
        "            'Seguranca e Correcao': 'Segurança e Correção',\n",
        "            'Resolucao da Duvida': 'Resolução da Dúvida',\n",
        "            'Facilidade de Entendimento': 'Facilidade de Entendimento',\n",
        "            'Citacao da Fonte': 'Citação da Fonte',\n",
        "            'Informacao Inventada': 'Informação Inventada'\n",
        "        }\n",
        "\n",
        "        # =================================================================\n",
        "        # 2.0 ANÁLISE DESCRITIVA\n",
        "        # =================================================================\n",
        "        latex_output.append(r\"\"\"\n",
        "\\section{Análise Descritiva das Avaliações}\n",
        "\\label{sec:descritiva}\n",
        "Inicialmente, foi realizada uma análise descritiva para visualizar a distribuição das avaliações para cada um dos cinco critérios. As tabelas a seguir apresentam a contagem absoluta e o percentual de cada categoria de resposta (N (\\%)), agrupadas por tipo de prompt.\n",
        "\"\"\")\n",
        "        for criterion_key, criterion_name in evaluation_criteria.items():\n",
        "            try:\n",
        "                df_filtered = df_total_consolidado.dropna(subset=[criterion_key, 'Abordagem'])\n",
        "                if df_filtered.empty: continue\n",
        "\n",
        "                crosstab = pd.crosstab(df_filtered['Abordagem'], df_filtered[criterion_key])\n",
        "                caption = f\"Análise descritiva para o critério “{escape_latex(criterion_name)}”.\"\n",
        "                label = f\"tab:desc_{criterion_key}\"\n",
        "                latex_output.append(generate_descriptive_table_latex(crosstab, caption, label))\n",
        "            except Exception as e:\n",
        "                latex_output.append(f\"\\n% Não foi possível gerar a análise descritiva para {criterion_name}: {e}\\n\")\n",
        "\n",
        "\n",
        "        # =================================================================\n",
        "        # 2.1 ANÁLISE DE CONCORDÂNCIA (Kappa de Fleiss)\n",
        "        # =================================================================\n",
        "        latex_output.append(r\"\"\"\n",
        "\\section{Análise de Concordância entre Avaliadores}\n",
        "\\label{sec:concordancia}\n",
        "\"\"\")\n",
        "\n",
        "        num_avaliadores = len(all_processed_dfs)\n",
        "        if num_avaliadores < 2:\n",
        "            latex_output.append(\"A análise de concordância interavaliador (Kappa de Fleiss) não foi realizada, pois requer no mínimo dois arquivos de avaliação.\\n\")\n",
        "        else:\n",
        "            latex_output.append(\n",
        "                fr\"\"\"\n",
        "Para quantificar o grau de concordância entre os {num_avaliadores} avaliadores, foi utilizado o coeficiente Kappa de Fleiss. Esta medida corrige a concordância que poderia ocorrer puramente ao acaso. A Tabela \\ref{{tab:kappa_fleiss}} apresenta os valores de Kappa calculados. Valores próximos a 1 indicam concordância perfeita, enquanto valores próximos de 0 indicam que a concordância não é melhor do que o acaso.\n",
        "\"\"\"\n",
        "            )\n",
        "\n",
        "            kappa_results = {}\n",
        "            for criterion_key, criterion_name in evaluation_criteria.items():\n",
        "                try:\n",
        "                    df_filtered_kappa = df_total_consolidado.dropna(subset=[criterion_key, 'Abordagem']).copy()\n",
        "\n",
        "                    contingency_matrix = df_filtered_kappa.groupby(['ID_Pergunta', 'Abordagem'])[criterion_key].value_counts().unstack(fill_value=0)\n",
        "                    contingency_matrix = contingency_matrix[contingency_matrix.sum(axis=1) >= 2]\n",
        "\n",
        "                    if contingency_matrix.shape[1] < 2:\n",
        "                        kappa_value = np.nan\n",
        "                    else:\n",
        "                        kappa_value = fleiss_kappa(contingency_matrix.values, method='fleiss')\n",
        "                    kappa_results[criterion_name] = kappa_value\n",
        "                except Exception:\n",
        "                    kappa_results[criterion_name] = np.nan\n",
        "\n",
        "            kappa_df = pd.DataFrame(list(kappa_results.items()), columns=['Critério de Avaliação', 'Valor de Kappa'])\n",
        "            kappa_df['Valor de Kappa'] = kappa_df['Valor de Kappa'].map(lambda x: f'{x:.4f}' if pd.notna(x) else 'nan')\n",
        "\n",
        "            latex_output.append(\n",
        "                kappa_df.to_latex(index=False, caption='Resultados do coeficiente Kappa de Fleiss para cada critério.', label='tab:kappa_fleiss', position='H', column_format='lc', header=[escape_latex(c) for c in kappa_df.columns])\n",
        "            )\n",
        "\n",
        "        # =================================================================\n",
        "        # 2.2 ANÁLISE COMPARATIVA DOS PROMPTS (Qui-Quadrado)\n",
        "        # =================================================================\n",
        "        latex_output.append(\n",
        "            r\"\"\"\n",
        "\\section{Análise Comparativa dos Tipos de Prompt}\n",
        "\\label{sec:comparacao_prompts}\n",
        "\n",
        "Para determinar se havia uma associação estatisticamente significativa entre o tipo de prompt e a avaliação recebida, foi empregado o teste Qui-quadrado de Independência ($\\chi^2$). A hipótese nula ($H_0$) é que as variáveis são independentes. Um valor-p inferior a 0.05 indica significância estatística.\n",
        "\"\"\"\n",
        "        )\n",
        "        for criterion_key, criterion_name in evaluation_criteria.items():\n",
        "            latex_output.append(f\"\\n\\\\subsection{{{escape_latex(criterion_name)}}}\\n\")\n",
        "            try:\n",
        "                df_filtered_chi2 = df_total_consolidado.dropna(subset=[criterion_key, 'Abordagem']).copy()\n",
        "\n",
        "                if df_filtered_chi2['Abordagem'].nunique() < 2 or df_filtered_chi2[criterion_key].nunique() < 2:\n",
        "                    latex_output.append(f\"Não foi possível realizar a análise Qui-quadrado para “{escape_latex(criterion_name)}” devido à falta de variação nos dados.\")\n",
        "                    continue\n",
        "\n",
        "                contingency_table = pd.crosstab(df_filtered_chi2['Abordagem'], df_filtered_chi2[criterion_key])\n",
        "                chi2, p, dof, _ = chi2_contingency(contingency_table)\n",
        "\n",
        "                p_value_text = 'menor' if p < 0.05 else 'maior'\n",
        "                conclusion_text = 'há evidências de uma associação estatisticamente significativa' if p < 0.05 else 'não há evidências de uma associação estatisticamente significativa'\n",
        "\n",
        "                latex_output.append(f\"O teste Qui-quadrado resultou em $\\\\chi^2({dof}) = {chi2:.4f}$, com um valor-p de ${p:.4f}$. Como o valor-p é {p_value_text} que 0.05, {conclusion_text} entre o tipo de prompt e a avaliação deste critério.\")\n",
        "\n",
        "                latex_output.append(generate_pgfplot_bar(contingency_table, f'Avaliações para “{criterion_name}”', 'Tipo de Prompt', 'Contagem de Avaliações', criterion_name))\n",
        "            except Exception as e:\n",
        "                latex_output.append(f\"Ocorreu um erro ao analisar o critério {criterion_name}: {e}\")\n",
        "\n",
        "        # =================================================================\n",
        "        # 2.3 ANÁLISE DE LEGIBILIDADE (ANOVA + TUKEY)\n",
        "        # =================================================================\n",
        "        latex_output.append(\n",
        "            r\"\"\"\n",
        "\\section{Análise do Nível de Linguagem}\n",
        "\\label{sec:legibilidade}\n",
        "\n",
        "A legibilidade das respostas foi avaliada objetivamente por meio de três índices da ferramenta \\texttt{textstat} (adaptada para o português):\n",
        "\\begin{itemize}\n",
        "    \\item \\textbf{Flesch Reading Ease (FRE):} Pontuações mais altas indicam maior facilidade de leitura (0-100).\n",
        "    \\item \\textbf{Flesch-Kincaid Grade Level (FKGL):} Estima os anos de escolaridade formal necessários para compreender o texto.\n",
        "    \\item \\textbf{SMOG Index:} Outro índice que estima os anos de escolaridade necessários.\n",
        "\\end{itemize}\n",
        "\n",
        "Para comparar as médias de legibilidade entre os três tipos de prompt, foi realizado um teste de Análise de Variância (ANOVA). Caso a ANOVA resultasse em um valor-p significativo (< 0.05), um teste \\textit{post-hoc} de Tukey HSD foi aplicado para identificar quais pares de prompts possuem médias estatisticamente diferentes.\n",
        "\"\"\"\n",
        "        )\n",
        "        try:\n",
        "            df_respostas_unicas = df_total_consolidado.drop_duplicates(subset=['ID_Pergunta', 'Abordagem']).copy()\n",
        "            textstat.set_lang('pt_BR')\n",
        "\n",
        "            for metric in ['flesch_reading_ease', 'flesch_kincaid_grade', 'smog_index']:\n",
        "                df_respostas_unicas[metric] = df_respostas_unicas['Resposta Gerada'].apply(lambda x: getattr(textstat, metric)(x) if isinstance(x, str) and x else np.nan)\n",
        "\n",
        "            df_respostas_unicas.dropna(subset=['flesch_reading_ease', 'Abordagem'], inplace=True)\n",
        "\n",
        "            readability_means = df_respostas_unicas.groupby('Abordagem')[['flesch_reading_ease', 'flesch_kincaid_grade', 'smog_index']].mean()\n",
        "            readability_means.columns = ['Média Flesch Reading Ease', 'Média Flesch-Kincaid Grade', 'Média SMOG Index']\n",
        "            latex_output.append(\n",
        "                readability_means.reset_index().rename(columns={'Abordagem':'Prompt'}).to_latex(index=False, float_format=\"%.2f\", caption='Médias das pontuações de legibilidade por tipo de prompt.', label='tab:legibilidade_means', position='H')\n",
        "            )\n",
        "\n",
        "            readability_metrics_map = {\n",
        "                'flesch_reading_ease': 'Flesch Reading Ease',\n",
        "                'flesch_kincaid_grade': 'Flesch-Kincaid Grade Level',\n",
        "                'smog_index': 'SMOG Index'\n",
        "            }\n",
        "\n",
        "            for metric_key, metric_name in readability_metrics_map.items():\n",
        "                latex_output.append(f\"\\n\\\\subsection{{Análise para {escape_latex(metric_name)}}}\\n\")\n",
        "\n",
        "                df_metric_filtered = df_respostas_unicas.dropna(subset=[metric_key])\n",
        "                prompt_groups = [df_metric_filtered[df_metric_filtered['Abordagem'] == prompt][metric_key] for prompt in ['Prompt CoT', 'Prompt Direto', 'Prompt Heurístico']]\n",
        "                valid_groups = [g for g in prompt_groups if not g.empty and len(g) > 1]\n",
        "\n",
        "                if len(valid_groups) < 2:\n",
        "                    latex_output.append(f\"Não foi possível realizar a análise para {metric_name}, pois não havia dados suficientes em pelo menos dois grupos de prompts.\")\n",
        "                    continue\n",
        "\n",
        "                stat_levene, p_levene = levene(*valid_groups)\n",
        "                levene_conclusion = \"não foi violado\" if p_levene >= 0.05 else \"foi violado\"\n",
        "                latex_output.append(f\"O teste de Levene para a homogeneidade das variâncias resultou em um valor-p de ${p_levene:.4f}$, indicando que o pressuposto de homogeneidade {levene_conclusion} (p $\\\\geq$ 0.05).\\n\")\n",
        "\n",
        "                f_stat, p_value = f_oneway(*valid_groups)\n",
        "                dof_between = len(valid_groups) - 1\n",
        "                dof_within = sum(len(g) for g in valid_groups) - len(valid_groups)\n",
        "\n",
        "                latex_output.append(f\"O teste ANOVA resultou em $F({dof_between}, {dof_within}) = {f_stat:.4f}$, com um valor-p de ${p_value:.4f}$. \")\n",
        "\n",
        "                if p_value < 0.05:\n",
        "                    latex_output.append(\"Este resultado indica que há uma diferença estatisticamente significativa em pelo menos um dos pares de médias de legibilidade. Para identificar quais pares são diferentes, foi realizado o teste de Tukey HSD (Tabela \\\\ref{{tab:tukey_{metric_key}}}).\\n\")\n",
        "\n",
        "                    tukey_results = pairwise_tukeyhsd(endog=df_metric_filtered[metric_key], groups=df_metric_filtered['Abordagem'], alpha=0.05)\n",
        "                    caption_tukey = f'Resultados do teste post-hoc de Tukey HSD para a métrica {escape_latex(metric_name)}.'\n",
        "                    label_tukey = f'tab:tukey_{metric_key}'\n",
        "                    latex_output.append(generate_tukey_latex(tukey_results, caption_tukey, label_tukey))\n",
        "                else:\n",
        "                    latex_output.append(\"Este resultado indica que não há uma diferença estatisticamente significativa nas médias de legibilidade entre os prompts para esta métrica.\\n\")\n",
        "\n",
        "                caption_box = f'Distribuição da pontuação de {escape_latex(metric_name)} para cada tipo de prompt.'\n",
        "                label_box = f\"legibilidade_{metric_key}\"\n",
        "                latex_output.append(generate_pgfplot_boxplot(df_metric_filtered, metric_key, f'Legibilidade ({metric_name}) por Tipo de Prompt', 'Tipo de Prompt', f'Pontuação {metric_name}', caption_box, label_box))\n",
        "\n",
        "        except Exception as e:\n",
        "            latex_output.append(f\"\\nOcorreu um erro ao realizar a análise de legibilidade: {traceback.format_exc()}\")\n",
        "\n",
        "        # =================================================================\n",
        "        # 3. IMPRESSÃO DO CÓDIGO LATEX FINAL\n",
        "        # =================================================================\n",
        "        print(\"\\n\\n\" + \"=\"*60)\n",
        "        print(\"    CÓDIGO LATEX GERADO COM SUCESSO (VERSÃO 6.5 - FINAL CORRIGIDO)    \")\n",
        "        print(\"=\"*60)\n",
        "        print(\"\\nCopie e cole o código abaixo diretamente no seu arquivo .tex.\\n\")\n",
        "        print(\"\\n\".join(latex_output))\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"\\nOcorreu um erro geral durante o processamento: {traceback.format_exc()}\")\n",
        "        print(\"\\nVerifique se os arquivos enviados estão corretos e se as colunas estão no formato esperado.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "_ZdpvmG90BFJ",
        "outputId": "f39f8a86-aaac-4e37-cf58-ed42f4761bf1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- PASSO 1: UPLOAD E PREPARAÇÃO DOS DADOS ---\n",
            "\n",
            "Por favor, faça o upload de UM OU MAIS arquivos de avaliação (.xlsx ou .csv).\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-01354bf1-0684-471e-96d2-adaf78ade4bc\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-01354bf1-0684-471e-96d2-adaf78ade4bc\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving Instrumento_avaliacao - LARISSA.xlsx to Instrumento_avaliacao - LARISSA (2).xlsx\n",
            "Saving instrumento_avaliacao_FINAL_GEMINI - fabricia 06.08.xlsx to instrumento_avaliacao_FINAL_GEMINI - fabricia 06.08 (2).xlsx\n",
            "Saving instrumento_avaliacao_FINAL_GEMINI_Marília.xlsx to instrumento_avaliacao_FINAL_GEMINI_Marília (2).xlsx\n",
            "\n",
            "Lendo e processando 3 arquivo(s)...\n",
            "  - Processando 'Instrumento_avaliacao - LARISSA (2).xlsx' como Avaliador(a) 1...\n",
            "  - Processando 'instrumento_avaliacao_FINAL_GEMINI - fabricia 06.08 (2).xlsx' como Avaliador(a) 2...\n",
            "  - Processando 'instrumento_avaliacao_FINAL_GEMINI_Marília (2).xlsx' como Avaliador(a) 3...\n",
            "Dados processados com sucesso.\n",
            "\n",
            "Iniciando a geração do relatório em LaTeX...\n",
            "\n",
            "\n",
            "============================================================\n",
            "    CÓDIGO LATEX GERADO COM SUCESSO (VERSÃO 6.5 - FINAL CORRIGIDO)    \n",
            "============================================================\n",
            "\n",
            "Copie e cole o código abaixo diretamente no seu arquivo .tex.\n",
            "\n",
            "% ===================================================================\n",
            "% INÍCIO DO CAPÍTULO DE RESULTADOS GERADO AUTOMATICAMENTE\n",
            "% Gerado em: 2025-08-06 16:22:24\n",
            "% Análise baseada em 3 arquivo(s) de avaliação.\n",
            "% Versão do Script: 6.5 (Final Corrigido)\n",
            "% ===================================================================\n",
            "%\n",
            "% CERTIFIQUE-SE DE QUE OS SEGUINTES PACOTES ESTÃO NO SEU ARQUIVO .tex PRINCIPAL:\n",
            "% \\usepackage{booktabs}\n",
            "% \\usepackage{float}\n",
            "% \\usepackage{tikz}\n",
            "% \\usepackage{pgfplots}\n",
            "% \\pgfplotsset{compat=1.18}\n",
            "%\n",
            "% ===================================================================\n",
            "\n",
            "\\chapter{Resultados}\n",
            "\\label{chap:resultados}\n",
            "\n",
            "Neste capítulo, são apresentados os resultados das análises estatísticas realizadas sobre as avaliações das respostas geradas por diferentes tipos de prompts. A análise aborda a distribuição geral das avaliações, a concordância entre os avaliadores, uma comparação da qualidade das respostas entre os prompts e uma avaliação objetiva da legibilidade dos textos.\n",
            "\n",
            "\n",
            "\\section{Análise Descritiva das Avaliações}\n",
            "\\label{sec:descritiva}\n",
            "Inicialmente, foi realizada uma análise descritiva para visualizar a distribuição das avaliações para cada um dos cinco critérios. As tabelas a seguir apresentam a contagem absoluta e o percentual de cada categoria de resposta (N (\\%)), agrupadas por tipo de prompt.\n",
            "\n",
            "\\begin{table}[H]\n",
            "\\caption{Análise descritiva para o critério “Segurança e Correção”.}\n",
            "\\label{tab:desc_Seguranca e Correcao}\n",
            "\\begin{tabular}{llllll}\n",
            "\\toprule\n",
            "Tipo de Prompt & A classificação foi realizada pensando na perspectiva do paciente. & Em parte & Não & Sim & Totalmente \\\\\n",
            "\\midrule\n",
            "Prompt CoT & 0 (0.0\\%) & 15 (20.5\\%) & 6 (8.2\\%) & 45 (61.6\\%) & 7 (9.6\\%) \\\\\n",
            "Prompt Direto & 1 (1.3\\%) & 15 (19.7\\%) & 8 (10.5\\%) & 44 (57.9\\%) & 8 (10.5\\%) \\\\\n",
            "Prompt Heurístico & 0 (0.0\\%) & 16 (21.3\\%) & 9 (12.0\\%) & 43 (57.3\\%) & 7 (9.3\\%) \\\\\n",
            "\\bottomrule\n",
            "\\end{tabular}\n",
            "\\end{table}\n",
            "\n",
            "\\begin{table}[H]\n",
            "\\caption{Análise descritiva para o critério “Resolução da Dúvida”.}\n",
            "\\label{tab:desc_Resolucao da Duvida}\n",
            "\\begin{tabular}{llll}\n",
            "\\toprule\n",
            "Tipo de Prompt & Não resolve & Resolve em parte & Resolve tudo \\\\\n",
            "\\midrule\n",
            "Prompt CoT & 15 (20.5\\%) & 18 (24.7\\%) & 40 (54.8\\%) \\\\\n",
            "Prompt Direto & 17 (22.7\\%) & 24 (32.0\\%) & 34 (45.3\\%) \\\\\n",
            "Prompt Heurístico & 18 (24.0\\%) & 17 (22.7\\%) & 40 (53.3\\%) \\\\\n",
            "\\bottomrule\n",
            "\\end{tabular}\n",
            "\\end{table}\n",
            "\n",
            "\n",
            "% Não foi possível gerar a análise descritiva para Facilidade de Entendimento: Cannot set a DataFrame with multiple columns to the single column Muito fácil\n",
            "\n",
            "\n",
            "% Não foi possível gerar a análise descritiva para Citação da Fonte: Cannot set a DataFrame with multiple columns to the single column Cita a fonte e a página\n",
            "\n",
            "\\begin{table}[H]\n",
            "\\caption{Análise descritiva para o critério “Informação Inventada”.}\n",
            "\\label{tab:desc_Informacao Inventada}\n",
            "\\begin{tabular}{lll}\n",
            "\\toprule\n",
            "Tipo de Prompt & Não & Sim \\\\\n",
            "\\midrule\n",
            "Prompt CoT & 67 (91.8\\%) & 6 (8.2\\%) \\\\\n",
            "Prompt Direto & 71 (94.7\\%) & 4 (5.3\\%) \\\\\n",
            "Prompt Heurístico & 70 (94.6\\%) & 4 (5.4\\%) \\\\\n",
            "\\bottomrule\n",
            "\\end{tabular}\n",
            "\\end{table}\n",
            "\n",
            "\n",
            "\\section{Análise de Concordância entre Avaliadores}\n",
            "\\label{sec:concordancia}\n",
            "\n",
            "\n",
            "Para quantificar o grau de concordância entre os 3 avaliadores, foi utilizado o coeficiente Kappa de Fleiss. Esta medida corrige a concordância que poderia ocorrer puramente ao acaso. A Tabela \\ref{tab:kappa_fleiss} apresenta os valores de Kappa calculados. Valores próximos a 1 indicam concordância perfeita, enquanto valores próximos de 0 indicam que a concordância não é melhor do que o acaso.\n",
            "\n",
            "\\begin{table}[H]\n",
            "\\caption{Resultados do coeficiente Kappa de Fleiss para cada critério.}\n",
            "\\label{tab:kappa_fleiss}\n",
            "\\begin{tabular}{lc}\n",
            "\\toprule\n",
            "Critério de Avaliação & Valor de Kappa \\\\\n",
            "\\midrule\n",
            "Segurança e Correção & nan \\\\\n",
            "Resolução da Dúvida & nan \\\\\n",
            "Facilidade de Entendimento & nan \\\\\n",
            "Citação da Fonte & nan \\\\\n",
            "Informação Inventada & nan \\\\\n",
            "\\bottomrule\n",
            "\\end{tabular}\n",
            "\\end{table}\n",
            "\n",
            "\n",
            "\\section{Análise Comparativa dos Tipos de Prompt}\n",
            "\\label{sec:comparacao_prompts}\n",
            "\n",
            "Para determinar se havia uma associação estatisticamente significativa entre o tipo de prompt e a avaliação recebida, foi empregado o teste Qui-quadrado de Independência ($\\chi^2$). A hipótese nula ($H_0$) é que as variáveis são independentes. Um valor-p inferior a 0.05 indica significância estatística.\n",
            "\n",
            "\n",
            "\\subsection{Segurança e Correção}\n",
            "\n",
            "O teste Qui-quadrado resultou em $\\chi^2(8) = 2.7149$, com um valor-p de $0.9510$. Como o valor-p é maior que 0.05, não há evidências de uma associação estatisticamente significativa entre o tipo de prompt e a avaliação deste critério.\n",
            "\\pgfplotstableread[col sep=comma]{Abordagem,aclassificaçãofoirealizadapensandonaperspectivadopaciente,emparte,não,sim,totalmente\n",
            "Prompt CoT,0,15,6,45,7\n",
            "Prompt Direto,1,15,8,44,8\n",
            "Prompt Heurístico,0,16,9,43,7\n",
            "}{\\dadosSegurançaeCorreção}\n",
            "\\begin{figure}[H]\n",
            "\\centering\n",
            "\\begin{tikzpicture}\n",
            "\\begin{axis}[\n",
            "    title={Avaliações para “Segurança e Correção”},\n",
            "ybar stacked,\n",
            "bar width=0.8cm,\n",
            "enlarge x limits={0.25},\n",
            "    xlabel={Tipo de Prompt},\n",
            "    ylabel={Contagem de Avaliações},\n",
            "    symbolic x coords={Prompt CoT, Prompt Direto, Prompt Heurístico},\n",
            "    xtick=data,\n",
            "x tick label style={rotate=45, anchor=east},\n",
            "    legend style={at={(0.5,1.1)}, anchor=south, legend columns=-1, /tikz/every even column/.append style={column sep=0.5cm}}\n",
            "]\n",
            "\\addplot table [x=Abordagem, y=aclassificaçãofoirealizadapensandonaperspectivadopaciente] {\\dadosSegurançaeCorreção};\n",
            "\\addplot table [x=Abordagem, y=emparte] {\\dadosSegurançaeCorreção};\n",
            "\\addplot table [x=Abordagem, y=não] {\\dadosSegurançaeCorreção};\n",
            "\\addplot table [x=Abordagem, y=sim] {\\dadosSegurançaeCorreção};\n",
            "\\addplot table [x=Abordagem, y=totalmente] {\\dadosSegurançaeCorreção};\n",
            "\\legend{A classificação foi realizada pensando na perspectiva do paciente., Em parte, Não, Sim, Totalmente}\n",
            "\\end{axis}\n",
            "\\end{tikzpicture}\n",
            "\\caption{Distribuição das avaliações para o critério “Segurança e Correção”.}\n",
            "\\label{fig:SegurançaeCorreção}\n",
            "\\end{figure}\n",
            "\n",
            "\\subsection{Resolução da Dúvida}\n",
            "\n",
            "O teste Qui-quadrado resultou em $\\chi^2(4) = 2.3232$, com um valor-p de $0.6766$. Como o valor-p é maior que 0.05, não há evidências de uma associação estatisticamente significativa entre o tipo de prompt e a avaliação deste critério.\n",
            "\\pgfplotstableread[col sep=comma]{Abordagem,Nãoresolve,Resolveemparte,Resolvetudo\n",
            "Prompt CoT,15,18,40\n",
            "Prompt Direto,17,24,34\n",
            "Prompt Heurístico,18,17,40\n",
            "}{\\dadosResoluçãodaDúvida}\n",
            "\\begin{figure}[H]\n",
            "\\centering\n",
            "\\begin{tikzpicture}\n",
            "\\begin{axis}[\n",
            "    title={Avaliações para “Resolução da Dúvida”},\n",
            "ybar stacked,\n",
            "bar width=0.8cm,\n",
            "enlarge x limits={0.25},\n",
            "    xlabel={Tipo de Prompt},\n",
            "    ylabel={Contagem de Avaliações},\n",
            "    symbolic x coords={Prompt CoT, Prompt Direto, Prompt Heurístico},\n",
            "    xtick=data,\n",
            "x tick label style={rotate=45, anchor=east},\n",
            "    legend style={at={(0.5,1.1)}, anchor=south, legend columns=-1, /tikz/every even column/.append style={column sep=0.5cm}}\n",
            "]\n",
            "\\addplot table [x=Abordagem, y=Nãoresolve] {\\dadosResoluçãodaDúvida};\n",
            "\\addplot table [x=Abordagem, y=Resolveemparte] {\\dadosResoluçãodaDúvida};\n",
            "\\addplot table [x=Abordagem, y=Resolvetudo] {\\dadosResoluçãodaDúvida};\n",
            "\\legend{Não resolve, Resolve em parte, Resolve tudo}\n",
            "\\end{axis}\n",
            "\\end{tikzpicture}\n",
            "\\caption{Distribuição das avaliações para o critério “Resolução da Dúvida”.}\n",
            "\\label{fig:ResoluçãodaDúvida}\n",
            "\\end{figure}\n",
            "\n",
            "\\subsection{Facilidade de Entendimento}\n",
            "\n",
            "O teste Qui-quadrado resultou em $\\chi^2(14) = 7.1995$, com um valor-p de $0.9267$. Como o valor-p é maior que 0.05, não há evidências de uma associação estatisticamente significativa entre o tipo de prompt e a avaliação deste critério.\n",
            "\\pgfplotstableread[col sep=comma]{Abordagem,Confusa,Maisoumenos,Muitofácil,RazoavelmenteFácil,Respostatécnica,Sim,muitofácil,éconfusatécnica\n",
            "Prompt CoT,6,5,2,14,1,30,14,1\n",
            "Prompt Direto,6,2,5,14,0,33,15,0\n",
            "Prompt Heurístico,7,3,3,15,0,33,14,0\n",
            "}{\\dadosFacilidadedeEntendimento}\n",
            "\\begin{figure}[H]\n",
            "\\centering\n",
            "\\begin{tikzpicture}\n",
            "\\begin{axis}[\n",
            "    title={Avaliações para “Facilidade de Entendimento”},\n",
            "ybar stacked,\n",
            "bar width=0.8cm,\n",
            "enlarge x limits={0.25},\n",
            "    xlabel={Tipo de Prompt},\n",
            "    ylabel={Contagem de Avaliações},\n",
            "    symbolic x coords={Prompt CoT, Prompt Direto, Prompt Heurístico},\n",
            "    xtick=data,\n",
            "x tick label style={rotate=45, anchor=east},\n",
            "    legend style={at={(0.5,1.1)}, anchor=south, legend columns=-1, /tikz/every even column/.append style={column sep=0.5cm}}\n",
            "]\n",
            "\\addplot table [x=Abordagem, y=Confusa] {\\dadosFacilidadedeEntendimento};\n",
            "\\addplot table [x=Abordagem, y=Maisoumenos] {\\dadosFacilidadedeEntendimento};\n",
            "\\addplot table [x=Abordagem, y=Muitofácil] {\\dadosFacilidadedeEntendimento};\n",
            "\\addplot table [x=Abordagem, y=RazoavelmenteFácil] {\\dadosFacilidadedeEntendimento};\n",
            "\\addplot table [x=Abordagem, y=Respostatécnica] {\\dadosFacilidadedeEntendimento};\n",
            "\\addplot table [x=Abordagem, y=Sim] {\\dadosFacilidadedeEntendimento};\n",
            "\\addplot table [x=Abordagem, y=muitofácil] {\\dadosFacilidadedeEntendimento};\n",
            "\\addplot table [x=Abordagem, y=éconfusatécnica] {\\dadosFacilidadedeEntendimento};\n",
            "\\legend{Confusa, Mais ou menos, Muito fácil, Razoavelmente fácil, Resposta técnica, Sim, Muito fácil, É confusa/técnica}\n",
            "\\end{axis}\n",
            "\\end{tikzpicture}\n",
            "\\caption{Distribuição das avaliações para o critério “Facilidade de Entendimento”.}\n",
            "\\label{fig:FacilidadedeEntendimento}\n",
            "\\end{figure}\n",
            "\n",
            "\\subsection{Citação da Fonte}\n",
            "\n",
            "O teste Qui-quadrado resultou em $\\chi^2(10) = 4.5764$, com um valor-p de $0.9176$. Como o valor-p é maior que 0.05, não há evidências de uma associação estatisticamente significativa entre o tipo de prompt e a avaliação deste critério.\n",
            "\\pgfplotstableread[col sep=comma]{Abordagem,Citaafonteeapágina,Citouafonteerrada,Citouapenasafonte,Nãocitouafonte,Sim,citaafonteeapágina\n",
            "Prompt CoT,16,0,1,16,26,13\n",
            "Prompt Direto,19,0,0,14,29,13\n",
            "Prompt Heurístico,19,1,0,15,27,13\n",
            "}{\\dadosCitaçãodaFonte}\n",
            "\\begin{figure}[H]\n",
            "\\centering\n",
            "\\begin{tikzpicture}\n",
            "\\begin{axis}[\n",
            "    title={Avaliações para “Citação da Fonte”},\n",
            "ybar stacked,\n",
            "bar width=0.8cm,\n",
            "enlarge x limits={0.25},\n",
            "    xlabel={Tipo de Prompt},\n",
            "    ylabel={Contagem de Avaliações},\n",
            "    symbolic x coords={Prompt CoT, Prompt Direto, Prompt Heurístico},\n",
            "    xtick=data,\n",
            "x tick label style={rotate=45, anchor=east},\n",
            "    legend style={at={(0.5,1.1)}, anchor=south, legend columns=-1, /tikz/every even column/.append style={column sep=0.5cm}}\n",
            "]\n",
            "\\addplot table [x=Abordagem, y=Citaafonteeapágina] {\\dadosCitaçãodaFonte};\n",
            "\\addplot table [x=Abordagem, y=Citouafonteerrada] {\\dadosCitaçãodaFonte};\n",
            "\\addplot table [x=Abordagem, y=Citouapenasafonte] {\\dadosCitaçãodaFonte};\n",
            "\\addplot table [x=Abordagem, y=Nãocitouafonte] {\\dadosCitaçãodaFonte};\n",
            "\\addplot table [x=Abordagem, y=Sim] {\\dadosCitaçãodaFonte};\n",
            "\\addplot table [x=Abordagem, y=citaafonteeapágina] {\\dadosCitaçãodaFonte};\n",
            "\\legend{Cita a fonte e a página, Citou a fonte errada, Citou apenas a fonte, Não citou a fonte, Sim, Cita a fonte e a página}\n",
            "\\end{axis}\n",
            "\\end{tikzpicture}\n",
            "\\caption{Distribuição das avaliações para o critério “Citação da Fonte”.}\n",
            "\\label{fig:CitaçãodaFonte}\n",
            "\\end{figure}\n",
            "\n",
            "\\subsection{Informação Inventada}\n",
            "\n",
            "O teste Qui-quadrado resultou em $\\chi^2(2) = 0.6739$, com um valor-p de $0.7139$. Como o valor-p é maior que 0.05, não há evidências de uma associação estatisticamente significativa entre o tipo de prompt e a avaliação deste critério.\n",
            "\\pgfplotstableread[col sep=comma]{Abordagem,Não,Sim\n",
            "Prompt CoT,67,6\n",
            "Prompt Direto,71,4\n",
            "Prompt Heurístico,70,4\n",
            "}{\\dadosInformaçãoInventada}\n",
            "\\begin{figure}[H]\n",
            "\\centering\n",
            "\\begin{tikzpicture}\n",
            "\\begin{axis}[\n",
            "    title={Avaliações para “Informação Inventada”},\n",
            "ybar stacked,\n",
            "bar width=0.8cm,\n",
            "enlarge x limits={0.25},\n",
            "    xlabel={Tipo de Prompt},\n",
            "    ylabel={Contagem de Avaliações},\n",
            "    symbolic x coords={Prompt CoT, Prompt Direto, Prompt Heurístico},\n",
            "    xtick=data,\n",
            "x tick label style={rotate=45, anchor=east},\n",
            "    legend style={at={(0.5,1.1)}, anchor=south, legend columns=-1, /tikz/every even column/.append style={column sep=0.5cm}}\n",
            "]\n",
            "\\addplot table [x=Abordagem, y=Não] {\\dadosInformaçãoInventada};\n",
            "\\addplot table [x=Abordagem, y=Sim] {\\dadosInformaçãoInventada};\n",
            "\\legend{Não, Sim}\n",
            "\\end{axis}\n",
            "\\end{tikzpicture}\n",
            "\\caption{Distribuição das avaliações para o critério “Informação Inventada”.}\n",
            "\\label{fig:InformaçãoInventada}\n",
            "\\end{figure}\n",
            "\n",
            "\\section{Análise do Nível de Linguagem}\n",
            "\\label{sec:legibilidade}\n",
            "\n",
            "A legibilidade das respostas foi avaliada objetivamente por meio de três índices da ferramenta \\texttt{textstat} (adaptada para o português):\n",
            "\\begin{itemize}\n",
            "    \\item \\textbf{Flesch Reading Ease (FRE):} Pontuações mais altas indicam maior facilidade de leitura (0-100).\n",
            "    \\item \\textbf{Flesch-Kincaid Grade Level (FKGL):} Estima os anos de escolaridade formal necessários para compreender o texto.\n",
            "    \\item \\textbf{SMOG Index:} Outro índice que estima os anos de escolaridade necessários.\n",
            "\\end{itemize}\n",
            "\n",
            "Para comparar as médias de legibilidade entre os três tipos de prompt, foi realizado um teste de Análise de Variância (ANOVA). Caso a ANOVA resultasse em um valor-p significativo (< 0.05), um teste \\textit{post-hoc} de Tukey HSD foi aplicado para identificar quais pares de prompts possuem médias estatisticamente diferentes.\n",
            "\n",
            "\\begin{table}[H]\n",
            "\\caption{Médias das pontuações de legibilidade por tipo de prompt.}\n",
            "\\label{tab:legibilidade_means}\n",
            "\\begin{tabular}{lrrr}\n",
            "\\toprule\n",
            "Prompt & Média Flesch Reading Ease & Média Flesch-Kincaid Grade & Média SMOG Index \\\\\n",
            "\\midrule\n",
            "Prompt CoT & -17.60 & 19.15 & 16.89 \\\\\n",
            "Prompt Direto & -23.77 & 19.70 & 15.84 \\\\\n",
            "Prompt Heurístico & -15.77 & 18.68 & 16.40 \\\\\n",
            "\\bottomrule\n",
            "\\end{tabular}\n",
            "\\end{table}\n",
            "\n",
            "\n",
            "\\subsection{Análise para Flesch Reading Ease}\n",
            "\n",
            "O teste de Levene para a homogeneidade das variâncias resultou em um valor-p de $0.1878$, indicando que o pressuposto de homogeneidade não foi violado (p $\\geq$ 0.05).\n",
            "\n",
            "O teste ANOVA resultou em $F(2, 72) = 0.8194$, com um valor-p de $0.4448$. \n",
            "Este resultado indica que não há uma diferença estatisticamente significativa nas médias de legibilidade entre os prompts para esta métrica.\n",
            "\n",
            "\\begin{figure}[H]\n",
            "\\centering\n",
            "\\begin{tikzpicture}\n",
            "\\begin{axis}[\n",
            "    title={Legibilidade (Flesch Reading Ease) por Tipo de Prompt},\n",
            "    xlabel={Tipo de Prompt},\n",
            "    ylabel={Pontuação Flesch Reading Ease},\n",
            "    boxplot/draw direction=y,\n",
            "xtick={1,2,3},\n",
            "    xticklabels={{Prompt CoT}, {Prompt Direto}, {Prompt Heurístico}},\n",
            "    x tick label style={rotate=45, anchor=east}\n",
            "]\n",
            "\\addplot+ [boxplot] table [row sep=\\\\, y index=0] { data \\\\ 13.69 \\\\ 5.13 \\\\ -19.98 \\\\ -35.87 \\\\ -34.91 \\\\ -24.84 \\\\ -61.34 \\\\ -28.76 \\\\ -42.97 \\\\ -22.30 \\\\ -7.35 \\\\ -33.32 \\\\ -17.63 \\\\ -9.03 \\\\ -15.93 \\\\ -19.84 \\\\ 20.96 \\\\ -9.78 \\\\ -2.54 \\\\ -13.90 \\\\ -16.52 \\\\ -12.98 \\\\ -4.89 \\\\ -21.84 \\\\ -23.20 \\\\ };\n",
            "\\addplot+ [boxplot] table [row sep=\\\\, y index=0] { data \\\\ -95.35 \\\\ 2.31 \\\\ -24.96 \\\\ -21.72 \\\\ -34.83 \\\\ 6.25 \\\\ -83.82 \\\\ -54.44 \\\\ -20.78 \\\\ -32.43 \\\\ -4.75 \\\\ -33.59 \\\\ -16.15 \\\\ 24.44 \\\\ -19.25 \\\\ -30.34 \\\\ -81.25 \\\\ -4.60 \\\\ -30.22 \\\\ -19.75 \\\\ -9.21 \\\\ -25.10 \\\\ -5.97 \\\\ 5.53 \\\\ 15.82 \\\\ };\n",
            "\\addplot+ [boxplot] table [row sep=\\\\, y index=0] { data \\\\ -7.50 \\\\ 5.41 \\\\ -35.87 \\\\ -30.39 \\\\ -22.34 \\\\ -26.59 \\\\ -80.11 \\\\ -49.50 \\\\ -21.09 \\\\ -19.14 \\\\ -4.75 \\\\ -26.24 \\\\ -10.60 \\\\ 6.47 \\\\ 9.72 \\\\ -19.84 \\\\ -1.00 \\\\ -3.98 \\\\ -8.88 \\\\ -29.42 \\\\ 4.31 \\\\ -26.87 \\\\ -1.29 \\\\ 11.04 \\\\ -5.74 \\\\ };\n",
            "\\end{axis}\n",
            "\\end{tikzpicture}\n",
            "\\caption{Distribuição da pontuação de Flesch Reading Ease para cada tipo de prompt.}\n",
            "\\label{fig:legibilidade_flesch_reading_ease}\n",
            "\\end{figure}\n",
            "\n",
            "\\subsection{Análise para Flesch-Kincaid Grade Level}\n",
            "\n",
            "O teste de Levene para a homogeneidade das variâncias resultou em um valor-p de $0.6249$, indicando que o pressuposto de homogeneidade não foi violado (p $\\geq$ 0.05).\n",
            "\n",
            "O teste ANOVA resultou em $F(2, 72) = 0.6722$, com um valor-p de $0.5138$. \n",
            "Este resultado indica que não há uma diferença estatisticamente significativa nas médias de legibilidade entre os prompts para esta métrica.\n",
            "\n",
            "\\begin{figure}[H]\n",
            "\\centering\n",
            "\\begin{tikzpicture}\n",
            "\\begin{axis}[\n",
            "    title={Legibilidade (Flesch-Kincaid Grade Level) por Tipo de Prompt},\n",
            "    xlabel={Tipo de Prompt},\n",
            "    ylabel={Pontuação Flesch-Kincaid Grade Level},\n",
            "    boxplot/draw direction=y,\n",
            "xtick={1,2,3},\n",
            "    xticklabels={{Prompt CoT}, {Prompt Direto}, {Prompt Heurístico}},\n",
            "    x tick label style={rotate=45, anchor=east}\n",
            "]\n",
            "\\addplot+ [boxplot] table [row sep=\\\\, y index=0] { data \\\\ 14.17 \\\\ 15.90 \\\\ 21.64 \\\\ 22.15 \\\\ 20.46 \\\\ 20.60 \\\\ 24.92 \\\\ 20.35 \\\\ 23.60 \\\\ 19.97 \\\\ 18.09 \\\\ 21.70 \\\\ 18.20 \\\\ 18.91 \\\\ 18.41 \\\\ 18.55 \\\\ 13.42 \\\\ 17.39 \\\\ 16.81 \\\\ 18.99 \\\\ 18.13 \\\\ 19.35 \\\\ 16.86 \\\\ 21.36 \\\\ 18.79 \\\\ };\n",
            "\\addplot+ [boxplot] table [row sep=\\\\, y index=0] { data \\\\ 28.05 \\\\ 16.17 \\\\ 21.71 \\\\ 21.01 \\\\ 20.17 \\\\ 17.60 \\\\ 27.93 \\\\ 23.83 \\\\ 18.95 \\\\ 19.22 \\\\ 18.02 \\\\ 20.76 \\\\ 17.75 \\\\ 13.08 \\\\ 18.51 \\\\ 20.32 \\\\ 26.08 \\\\ 17.71 \\\\ 20.51 \\\\ 19.16 \\\\ 18.02 \\\\ 19.54 \\\\ 17.77 \\\\ 16.46 \\\\ 14.24 \\\\ };\n",
            "\\addplot+ [boxplot] table [row sep=\\\\, y index=0] { data \\\\ 16.29 \\\\ 16.11 \\\\ 21.99 \\\\ 21.60 \\\\ 18.31 \\\\ 21.36 \\\\ 26.84 \\\\ 23.27 \\\\ 19.12 \\\\ 19.90 \\\\ 18.02 \\\\ 19.90 \\\\ 17.62 \\\\ 15.09 \\\\ 15.01 \\\\ 18.55 \\\\ 16.79 \\\\ 17.79 \\\\ 17.04 \\\\ 21.17 \\\\ 15.64 \\\\ 20.90 \\\\ 16.36 \\\\ 15.53 \\\\ 16.86 \\\\ };\n",
            "\\end{axis}\n",
            "\\end{tikzpicture}\n",
            "\\caption{Distribuição da pontuação de Flesch-Kincaid Grade Level para cada tipo de prompt.}\n",
            "\\label{fig:legibilidade_flesch_kincaid_grade}\n",
            "\\end{figure}\n",
            "\n",
            "\\subsection{Análise para SMOG Index}\n",
            "\n",
            "O teste de Levene para a homogeneidade das variâncias resultou em um valor-p de $0.8843$, indicando que o pressuposto de homogeneidade não foi violado (p $\\geq$ 0.05).\n",
            "\n",
            "O teste ANOVA resultou em $F(2, 72) = 1.0631$, com um valor-p de $0.3507$. \n",
            "Este resultado indica que não há uma diferença estatisticamente significativa nas médias de legibilidade entre os prompts para esta métrica.\n",
            "\n",
            "\\begin{figure}[H]\n",
            "\\centering\n",
            "\\begin{tikzpicture}\n",
            "\\begin{axis}[\n",
            "    title={Legibilidade (SMOG Index) por Tipo de Prompt},\n",
            "    xlabel={Tipo de Prompt},\n",
            "    ylabel={Pontuação SMOG Index},\n",
            "    boxplot/draw direction=y,\n",
            "xtick={1,2,3},\n",
            "    xticklabels={{Prompt CoT}, {Prompt Direto}, {Prompt Heurístico}},\n",
            "    x tick label style={rotate=45, anchor=east}\n",
            "]\n",
            "\\addplot+ [boxplot] table [row sep=\\\\, y index=0] { data \\\\ 13.56 \\\\ 15.90 \\\\ 21.86 \\\\ 20.58 \\\\ 15.11 \\\\ 18.46 \\\\ 19.54 \\\\ 17.55 \\\\ 20.50 \\\\ 17.41 \\\\ 16.32 \\\\ 17.69 \\\\ 15.25 \\\\ 18.24 \\\\ 15.90 \\\\ 13.56 \\\\ 11.98 \\\\ 16.06 \\\\ 15.08 \\\\ 19.03 \\\\ 14.07 \\\\ 18.24 \\\\ 15.58 \\\\ 20.27 \\\\ 14.37 \\\\ };\n",
            "\\addplot+ [boxplot] table [row sep=\\\\, y index=0] { data \\\\ 13.02 \\\\ 15.65 \\\\ 21.19 \\\\ 20.74 \\\\ 14.19 \\\\ 17.12 \\\\ 20.27 \\\\ 17.51 \\\\ 16.83 \\\\ 12.69 \\\\ 15.90 \\\\ 17.88 \\\\ 13.82 \\\\ 11.21 \\\\ 15.02 \\\\ 15.11 \\\\ 11.21 \\\\ 16.93 \\\\ 14.84 \\\\ 16.73 \\\\ 15.38 \\\\ 16.40 \\\\ 16.65 \\\\ 14.55 \\\\ 15.25 \\\\ };\n",
            "\\addplot+ [boxplot] table [row sep=\\\\, y index=0] { data \\\\ 12.16 \\\\ 15.58 \\\\ 19.29 \\\\ 20.27 \\\\ 14.55 \\\\ 20.58 \\\\ 18.60 \\\\ 17.69 \\\\ 16.53 \\\\ 18.24 \\\\ 15.90 \\\\ 18.24 \\\\ 15.38 \\\\ 13.02 \\\\ 15.90 \\\\ 13.30 \\\\ 13.02 \\\\ 18.24 \\\\ 13.62 \\\\ 19.62 \\\\ 14.19 \\\\ 19.29 \\\\ 15.25 \\\\ 16.32 \\\\ 15.25 \\\\ };\n",
            "\\end{axis}\n",
            "\\end{tikzpicture}\n",
            "\\caption{Distribuição da pontuação de SMOG Index para cada tipo de prompt.}\n",
            "\\label{fig:legibilidade_smog_index}\n",
            "\\end{figure}\n"
          ]
        }
      ]
    }
  ]
}